{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a6985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 16:08:38.729886: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-22 16:08:38.773726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-22 16:08:38.773761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-22 16:08:38.774821: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-22 16:08:38.781779: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-22 16:08:39.610938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check GPU runtime type... \n",
      "Change Runtype Type in top menu for GPU acceleration\n",
      " \"Runtime\" -> \"Change Runtime Type\" -> \"GPU\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 16:08:43.621093: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-22 16:08:43.622161: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5316 protein-pocket pairs.\n",
      "Input shape: torch.Size([4, 32, 32, 32])\n",
      "Label shape: torch.Size([1, 32, 32, 32])\n",
      "Pocket voxels in label: 367.0\n",
      "5305\n"
     ]
    }
   ],
   "source": [
    "%run data_splitting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5fdb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698f04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabbc2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5215e1",
   "metadata": {},
   "source": [
    "# **Building predictor**    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa8af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pocket3DCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4):  # 4 = atom types: C, N, O, S\n",
    "        super(Pocket3DCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(128, 1, kernel_size=1),  # 1 output channel = binary classification\n",
    "            nn.Sigmoid()  # voxel-wise output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # output shape: (batch, 1, D, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a339e4",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4caedca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pocket3DCNN(in_channels=4)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66982e3a",
   "metadata": {},
   "source": [
    "We calculate the evaluation metrics scores with **custom functions**, so that is more **Pytorch-tensor frindly**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab one sample from the dataset\n",
    "X, Y = dataset[3]\n",
    "\n",
    "X_input = X.unsqueeze(0)  \n",
    "\n",
    "# run the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_input = X_input.to(device)  \n",
    "    preds = model(X_input)[0]  # remove batch dimension again, shape: (1, 32, 32, 32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3ca468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    preds = preds > 0.5 \n",
    "    correct = (preds == labels).sum().item()\n",
    "    total = labels.numel()\n",
    "    return correct / total\n",
    "\n",
    "def precision(preds, labels, threshold=0.5):\n",
    "    preds_bin = (preds > threshold).cpu().numpy().flatten()\n",
    "    labels_bin = labels.cpu().numpy().flatten()\n",
    "    return precision_score(labels_bin, preds_bin, zero_division=0)\n",
    "\n",
    "def recall(preds, labels, threshold=0.5):\n",
    "    preds_bin = (preds > threshold).cpu().numpy().flatten()\n",
    "    labels_bin = labels.cpu().numpy().flatten()\n",
    "    return recall_score(labels_bin, preds_bin, zero_division=0)\n",
    "\n",
    "\n",
    "def f1_score(prec, rec, eps=1e-8):\n",
    "    return 2 * prec * rec / (prec + rec + eps)\n",
    "\n",
    "def dice_loss(probs, target, smooth=1e-8):\n",
    "    target = target.to(preds.device)\n",
    "\n",
    "    # dice Loss\n",
    "    intersection = (probs * target).sum()\n",
    "    dice_score = (2. * intersection + smooth) / (probs.sum() + target.sum() + smooth)\n",
    "    loss = 1 - dice_score\n",
    "\n",
    "    return loss\n",
    "\n",
    "pos_weight = torch.tensor([10.0], device=device) \n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0ac13",
   "metadata": {},
   "source": [
    "We measure:\n",
    "\n",
    "    - accuracy\n",
    "    - precision\n",
    "    - recall\n",
    "    - f1_score\n",
    "    - BCE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd0d24c",
   "metadata": {},
   "source": [
    "#### Checkpoint functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad68ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading checkpoint\n",
    "def load_checkpoint(model, optimizer, filename='checkpoint.pth'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from epoch {epoch}.\")\n",
    "    return model, optimizer, epoch, loss\n",
    "\n",
    "# Saving checkpoint\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename='checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122bb0a5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9012c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loader   = DataLoader(val_set, batch_size=2, shuffle=False)\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True)\n",
    "test_loader  = DataLoader(test_set, batch_size=2, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "# === Metric tracking ===\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, train_recalls, train_pres, train_f1 = [], [], [], []\n",
    "val_accuracies, val_recalls, val_pres, val_f1 = [], [], [], []\n",
    "\n",
    "# === Checkpoint handling ===\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550bd7b5",
   "metadata": {},
   "source": [
    "### Training (fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99690e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65306/3332145685.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename)\n",
      "/tmp/ipykernel_65306/1650111527.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from epoch 60.\n",
      "Resuming from epoch 60\n",
      "\n",
      " Evaluating on test set: \n",
      "\n",
      " Final test results:\n",
      "Loss:      0.7472\n",
      "Accuracy:  0.9814\n",
      "Recall:    0.5500\n",
      "Precision: 0.3157\n",
      "F1 Score:  0.3923\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model, optimizer, start_epoch, _ = load_checkpoint(model, optimizer, 'model_checkpoint.pth')\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "except FileNotFoundError:\n",
    "    start_epoch = 0\n",
    "    print(\"No checkpoint found, starting from scratch.\")\n",
    "\n",
    "# === Training Loop ===\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    total_loss = correct_train = total_train = 0\n",
    "    total_train_recall = total_pres = total_f1 = 0\n",
    "\n",
    "    for i, (X, Y) in enumerate(train_loader):\n",
    "        batch_start = time.time()\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        acc = accuracy(preds, Y)\n",
    "        rec = recall(preds, Y)\n",
    "        pres = precision(preds, Y)\n",
    "        f1 = f1_score(pres, rec)\n",
    "\n",
    "        correct_train += acc\n",
    "        total_train += 1\n",
    "        total_train_recall += rec\n",
    "        total_pres += pres\n",
    "        total_f1 += f1\n",
    "\n",
    "        batch_time = time.time() - batch_start\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Batch {i+1}/{len(train_loader)} | Loss: {loss.item():.4f} | Time: {batch_time:.2f}\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "\n",
    "    # Average training metrics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_accuracy = correct_train / total_train\n",
    "    avg_recall = total_train_recall / total_train\n",
    "    avg_pres = total_pres / total_train\n",
    "    avg_f1 = total_f1 / total_train\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(avg_accuracy)\n",
    "    train_recalls.append(avg_recall)\n",
    "    train_pres.append(avg_pres)\n",
    "    train_f1.append(avg_f1)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Train | Loss: {avg_loss:.4f}, Acc: {avg_accuracy:.4f}, Recall: {avg_recall:.4f}, Precision: {avg_pres:.4f}, F1: {avg_f1:.4f}\")\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = correct_val = total_val = total_val_recall = total_val_pres = total_val_f1 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, Y_val in val_loader:\n",
    "            X_val, Y_val = X_val.to(device), Y_val.to(device)\n",
    "            preds_val = model(X_val)\n",
    "            loss_val = loss_fn(preds_val, Y_val)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "            acc_val = accuracy(preds_val, Y_val)\n",
    "            rec_val = recall(preds_val, Y_val)\n",
    "            pres_val = precision(preds_val, Y_val)\n",
    "            f1_val = f1_score(pres_val, rec_val)\n",
    "\n",
    "            correct_val += acc_val\n",
    "            total_val += 1\n",
    "            total_val_recall += rec_val\n",
    "            total_val_pres += pres_val\n",
    "            total_val_f1 += f1_val\n",
    "\n",
    "    # Average validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_accuracy = correct_val / total_val\n",
    "    avg_val_recall = total_val_recall / total_val\n",
    "    avg_val_pres = total_val_pres / total_val\n",
    "    avg_val_f1 = total_val_f1 / total_val\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(avg_val_accuracy)\n",
    "    val_recalls.append(avg_val_recall)\n",
    "    val_f1.append(avg_val_f1)\n",
    "    val_pres.append(avg_val_pres)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Val   | Loss: {avg_val_loss:.4f}, Acc: {avg_val_accuracy:.4f}, Recall: {avg_val_recall:.4f}, Precision: {avg_val_pres:.4f}, F1: {avg_val_f1:.4f}\")\n",
    "\n",
    "    save_checkpoint(model, optimizer, epoch+1, avg_loss, filename=\"model_checkpoint.pth\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        print(\"Best model saved\")\n",
    "\n",
    "# === Final Test Evaluation ==='''\n",
    "\n",
    "print(\"\\n Evaluating on test set: \")\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = correct_test = total_test = total_test_recall = total_test_pres = total_test_f1 = 0\n",
    "model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    for X_test, Y_test in test_loader:\n",
    "        X_test, Y_test = X_test.to(device), Y_test.to(device)\n",
    "        preds_test = model(X_test)\n",
    "        loss_test = loss_fn(preds_test, Y_test)\n",
    "        test_loss += loss_test.item()\n",
    "\n",
    "        acc_test = accuracy(preds_test, Y_test)\n",
    "        rec_test = recall(preds_test, Y_test)\n",
    "        pres_test = precision(preds_test, Y_test)\n",
    "        f1_test = f1_score(pres_test, rec_test)\n",
    "\n",
    "        correct_test += acc_test\n",
    "        total_test += 1\n",
    "        total_test_recall += rec_test\n",
    "        total_test_pres += pres_test\n",
    "        total_test_f1 += f1_test\n",
    "\n",
    "print(f\"\\n Final test results:\")\n",
    "print(f\"Loss:      {test_loss / len(test_loader):.4f}\")\n",
    "print(f\"Accuracy:  {correct_test / total_test:.4f}\")\n",
    "print(f\"Recall:    {total_test_recall / total_test:.4f}\")\n",
    "print(f\"Precision: {total_test_pres / total_test:.4f}\")\n",
    "print(f\"F1 Score:  {total_test_f1 / total_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_metrics = {\n",
    "    \"train\": {\n",
    "        \"loss\": train_losses,\n",
    "        \"acc\": train_accuracies,\n",
    "        \"recall\": train_recalls,\n",
    "        \"precision\": train_pres,\n",
    "        \"f1\": train_f1\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"loss\": val_losses,\n",
    "        \"acc\": val_accuracies,\n",
    "        \"recall\": val_recalls,\n",
    "        \"precision\": val_pres,\n",
    "        \"f1\": val_f1\n",
    "    },\n",
    "    \"test\": {\n",
    "    \"loss\": test_loss / total_test,\n",
    "    \"accuracy\": correct_test / total_test,\n",
    "    \"recall\": total_test_recall / total_test,\n",
    "    \"precision\": total_test_pres / total_test,\n",
    "    \"f1_score\": total_test_f1 / total_test\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"all_metrics.json\", \"w\") as f:\n",
    "    json.dump(all_metrics, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
